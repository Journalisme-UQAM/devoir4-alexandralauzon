#coding: utf-8

### MERCI ALEXANDRA! VOICI QUELQUES COMMENTAIRES SUR TON SCRIPT, TOUJOURS EN MAJ. PRÃ‰CÃ‰DÃ‰S DE 3#

#ici, j'importe csv, le module spacy et counter pour compter les frÃ©quences
import csv, spacy
from collections import Counter
#j'identifie ensuite mon fichier sous le nom martino
# martino = "martino.csv"
martino = "../martino.csv" ### JE CHANGE LE CHEMIN POUR QUE Ã‡A MARCHE SUR MON ORDI.
#ici je lis mon fichier
f = open(martino)
articles = csv.reader(f)
next(articles)
#j'installe mon modÃ¨le qui permet d'analyse le franÃ§ais
tal = spacy.load("fr_core_news_md")
#ici, je crÃ©e deux listes que je vais utiliser plus tard compter les lignes de mon fichier
tousMots = []
bigrams = []
#j'ouvre ensuite ma bouche principale
for article in articles:
    print(article[1]) ### J'IMPRIME LA DATE 
    doc = tal(article[3]) #il y a 4 Ã©lÃ©ments dans ma liste, et je veux le dernier Ã©lÃ©ment (texte) donc je mets le #3 ### EXCELLENT
    # for token in doc:
        # print(token.text)
    # lemmes = [token.lemma_ for token in doc] #je lemmatise mon texte ### C'EST BIEN, MAIS TU LE FAIS AUSSI DANS TON BLOC DE CODE QUI SUIT
    # print(lemmes)
    # print(len(lemmes))

    # mots = [token.lemma_ for token in doc if token.is_stop == False and token.is_punct == False and token.text == "islam" and token.text == "muslim"] #ici, j'enlÃ¨ve les mots vides (token.is_stop), j'enlÃ¨ve la ponctuation (token.is_punct) et je garde tous les mots contenant "islam" et "muslim" (token.text)
    ### TON APPROCHE EST INTÃ‰RESSANTE; POUR QU'ELLE FONCTIONNE, IL AURAIT FALLU LA MODIFIER AINSI:
    # mots = [token.lemma_ for token in doc if token.is_stop == False and token.is_punct == False and ("islam" in token.lemma_ or "musulm" in token.lemma_)] ### LA DIFFÃ‰RENCE EST QUE CE CODE TIENT DEMANDE SI LA CHAÃŽNE DE CARACTÃˆRE Â«ISLAM*Â» OU Â«MUSULM*Â» EST INCLUSE DANS LE MOT LEMMATISÃ‰, ALORS QUE TON CODE DEMANDAIT SI CE MOT Ã‰TAIT ABSOLUMENT Â«ISLAMÂ» OU Â«MUSLIMÂ» (POURQUOI Â«MUSLIMÂ», D'AILLEURS?)
    ### MAIS CETTE APPROCHE FAIT EN SORTE QUE TU PERDS TOUS LES MOTS QUI VIENNENT AVANT OU APRÃˆS Â«ISLAMÂ» OU Â«MUSULMÂ»; IL EST IMPORTANT DE LES CONSERVER (ON FERA LE TRI APRÃˆS), DONC, ON VA PLUTÃ”T Ã‰CRIRE CE CODE:
    mots = [token.lemma_ for token in doc if token.is_stop == False and token.is_punct == False]
    # print(mots)
    print(len(mots))

    for mot in mots:
        tousMots.append(mot) #ceci est ma grande liste avec tous les mots rÃ©sultants de la boucle
        # print(tousMots)

    for x, y in enumerate(mots[:-1]):
        ### C'EST ICI QU'ON PEUT FAIRE LE TRI ET NE CONSERVER QUE LES MOTS QUI CONTIENNENT "ISLAM" OU "MUSULM"
        if "islam" in mots[x] or "musulm" in mots[x]:
            bigrams.append("{} {}".format(mots[x],mots[x+1])) #avec Ã§a, je peux faire des paires de mots, afin de voir plus tard quelle paire de mots est la plus utilisÃ©e dans les textes ### TON CODE Ã‰TAIT BON; IL NE MANQUAIT QUE LA CONDITION DE LA LIGNE PRÃ‰CÃ‰DENTE
    # print(bigrams)
    print(len(bigrams)) ### SIMPLE AFFICHAGE POUR SAVOIR OÃ™ ON EST RENDU
    print("ðŸŒˆ"*40) ### PETIT SÃ‰PARATEUR DANS L'AIR DU TEMPS

freq = Counter(bigrams) 
print(freq.most_common(50)) #je peux finalement obtenir les cinquantes paires de mots les plus utilisÃ©es dans les textes de Richard Martineau.

#Malheureusement, Ã§a ne fonctionne pas. Je sais que c'est au niveau de la ligne 26 que Ã§a bloque, mais je ne sais pas comment rÃ©gler le problÃ¨me, mÃªme si je cherche sur internet. Je ne suis pas certaine que "token.text == "muslim" " est la bonne formule. Par contre, je ne saurais pas comment cibler ces deux mots autrement avec spacy. 
### EN ESPÃ‰RANT QUE MES COMMENTAIRES AUX LIGNES 43 ET 45 AIENT PU T'AIDER Ã€ COMPRENDRE CE QUI SE PASSAIT :)